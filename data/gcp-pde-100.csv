id,question,answer,exam,section
3672548206,You have built a machine learning model that is overfitting. What technique would you try to eliminate overfitting?,Regularization,gcp-pde,flashcard
2191993906,What is Cloud SQL?,It is GCP's managed relational database service. It includes options to run MySQL and PostgreSQL. SQL Server is also available in beta.,gcp-pde,flashcard
4073852575,What is object storage?,"A storage system that manages data as objects, such as files. Cloud Storage is an object storage system.",gcp-pde,flashcard
2299242714,What is the Sarbanes–Oxley Act (SOX)?,The Sarbanes–Oxley Act is a U.S. financial reporting regulation governing publicly traded companies.,gcp-pde,flashcard
2995056801,What GCP service offers fully managed MySQL and PostgreSQL databases?,Cloud SQL,gcp-pde,flashcard
1313495479,"As a database administrator tasked with migrating a MongoDB instance to Google Cloud, you are concerned about your ability to configure the database optimally. You want to collect metrics at both the instance level and the database server level. What would you do in addition to creating an instance and installing and configuring MongoDB to ensure that you can monitor key instances and database metrics?",Install Stackdriver Monitoring agent.  installing Stackdriver Monitoring agent. This will collect application-level metrics and send them to Stackdriver for alerting and charting.,gcp-pde,Building and Operationalizing Storage Systems
4033049464,What is multi-regional storage?,A class of Cloud Storage that stores objects in at least two separate geographic places that are separated by at least 100 miles. This practice of storing objects in separate geographic areas is called geo-redundant storage.,gcp-pde,flashcard
2348375541,"Auditors have informed your company CFO that to comply with a new regulation, your company will need to ensure that financial reporting data is kept for at least three years. The CFO asks for your advice on how to comply with the regulation with the least administrative overhead. What would you recommend?",Define a data retention policy. A data retention policy will ensure that files are not deleted from a storage bucket until they reach a specified age.,gcp-pde,Building and Operationalizing Storage Systems
1218290395,Which GCP service is used for managing and reviewing logs?,Stackdriver Logging,gcp-pde,flashcard
4053436800,What GCP service provides managed in-memory caching?,Cloud Memorystore,gcp-pde,flashcard
934994031,"Which storage classes are good options for infrequently accessed data? One is designed to be accessed no more than once a month, and the other is designed to be accessed no more than once per year.",Nearline (once per month) and Coldline (once per year),gcp-pde,flashcard
799496378,You need to build a chatbot to reduce the burden on your customer support department. What GCP service would you use?,DialogFlow,gcp-pde,flashcard
4017046496,What kind of databases do not use the relational model and do not require a fixed structure or schema?,NoSQL databases,gcp-pde,flashcard
2179034163,What kind of services reduce the workload on systems administrators and DevOps engineers because they eliminate some of the work required when managing your own implementation of a platform?,Managed services,gcp-pde,flashcard
771928322,What are some key factors to keep in mind when choosing a storage solution?,"Read and write patterns, consistency, transaction support, cost, and latency",gcp-pde,flashcard
3575974253,Your department is experimenting with using Cloud Spanner for a globally accessible database. You are starting with a pilot project using a regional instance. You would like to follow Google’s recommendations for the maximum sustained CPU utilization of a regional instance. What is the maximum CPU utilization that you would target?,65%.  65%.,gcp-pde,Building and Operationalizing Storage Systems
1396148492,"If you don't want a BigQuery query to count against your resources, how should you run it?",Batch,gcp-pde,flashcard
2299195618,"You have trained a machine learning model, and it works well on training data but not on test data or when used in production. What is the likely cause of the problem?",Overfitting,gcp-pde,flashcard
2926098365,What is a service-level objective (SLO)?,A service-level objective is an agreed-upon target for a measurable attribute of a service.,gcp-pde,flashcard
169171073,You are responsible for developing an ingestion mechanism for a large number of IoT sensors. The ingestion service should accept data up to 10 minutes late. The service should also perform some transformations before writing the data to a database. Which of the managed services would be the best option for managing late arriving data and performing transformations?,Cloud Dataflow. Cloud Dataflow is a stream and batch processing service that is used for transforming data and processing streaming data.,gcp-pde,Selecting Appropriate Storage Technologies
2348764550,What GCP service could you use as a replacement for Apache Kafka?,Cloud Pub/Sub,gcp-pde,flashcard
2047913685,What type of VM can run for up to 24 hours before being shut down by Google Cloud?,Preemptible VMs,gcp-pde,flashcard
3962731188,"You created a Cloud SQL database that uses replication to improve read performance. Occasionally, the read replica will be unavailable. You haven’t noticed a pattern, but the disruptions occur once or twice a month. No DBA operations are occurring when the incidents occur. What might be the cause of this issue?","Maintenance is occurring on the read replica. Maintenance could be occurring. Maintenance on read replicas is not restricted to the maintenance window of the primary instance or to other windows, so it can occur anytime. That would make the read replica unavailable.",gcp-pde,Building and Operationalizing Storage Systems
519977413,A multinational corporation is building a global inventory database. The database will support OLTP type transactions at a global scale. Which of the following would you consider as possible databases for the system?,Cloud Spanner only. Cloud Spanner is the only globally scalable relational database for OLTP applications.,gcp-pde,Selecting Appropriate Storage Technologies
623694209,"A genomics research institute is developing a platform for analyzing data related to genetic diseases. The genomics data is in a specialized format known as FASTQ, which stores nucleotide sequences and quality scores in a text format. Files may be up to 400 GB and are uploaded in batches. Once the files finish uploading, an analysis pipeline runs, reads the data in the FASTQ file, and outputs data to a database. What storage system is a good option for storing the uploaded FASTQ data?","Cloud Storage. because the FASTQ files are unstructured since their internal format is not used to organize storage structures. Also, 400 GB is large enough that it is not efficient to store them as objects in a database.",gcp-pde,Selecting Appropriate Storage Technologies
1458385330,What is a measure of the probability that a service will continue to function under some load for a period of time?,Reliability,gcp-pde,flashcard
3674333551,What GCP service is useful for buffering data between services?,Cloud Pub/Sub,gcp-pde,flashcard
1594354996,"When long-term archival storage is required, what GCP service is the best option?",Cloud Storage,gcp-pde,flashcard
2705101997,What is a pull subscription in Cloud Pub/Sub?,A pull subscription in Cloud Pub/Sub is a subscription in which a service reads a message from a topic instead of waiting for it to be sent.,gcp-pde,flashcard
2508014661,What GCP service could you use as a replacement for Apache Flink?,Cloud Dataflow,gcp-pde,flashcard
1127981209,You want to build a machine learning model to predict the selling price of houses. What kind of model would you build?,Regression model,gcp-pde,flashcard
2436519950,"What Google Cloud databases are used for relational, transaction-oriented applications?",Cloud SQL and Cloud Spanner,gcp-pde,flashcard
546605469,A team of analysts has collected several terabytes of telemetry data in CSV datasets. They plan to store the datasets in GCP and query and analyze the data using SQL. Which of the following is the most appropriate GCP storage service for the datasets?,"BigQuery.  BigQuery, which is a managed analytical database service that supports SQL and scales to petabyte volumes of data.",gcp-pde,Selecting Appropriate Storage Technologies
1652326711,"You have been hired to consult with a startup that is developing software for self-driving vehicles. The company’s product uses machine learning to predict the trajectory of persons and vehicles. Currently, the software is being developed using 20 vehicles, all located in the same city. IoT data is sent from vehicles every 60 seconds to a MySQL database running on a Compute Engine instance using an n2-standard-8 machine type with 8 vCPUs and 16 GB of memory. The startup wants to review their architecture and make any necessary changes to support tens of thousands of self-driving vehicles, all transmitting IoT data every second. The vehicles will be located across North America and Europe. Approximately 4 KB of data is sent in each transmission. What changes to the architecture would you recommend?","Replace Cloud SQL with Bigtable. Bigtable is the best storage service for IoT data, especially when a large number of devices will be sending data at short intervals.",gcp-pde,Selecting Appropriate Storage Technologies
3460808410,"A software-as-a-service (SaaS) company specializing in automobile IoT sensors collects streaming time-series data from tens of thousands of vehicles. The vehicles are owned and operated by 40 different companies, who are the primary customers of the SaaS company. The data will be stored in Bigtable using a multitenant database; that is, all customer data will be stored in the same database. The data sent from the IoT device includes a sensor ID, which is globally unique; a timestamp; and several metrics about engine efficiency. Each customer will query their own data only. Which of the following would you use as a row-key?","Customer ID, sensor ID, timestamp. The database is multitenant, so each tenant, or customer, will query only its own data, so all that data should be in close proximity. Using customer ID first accomplishes this. Next, the sensor ID is globally unique, so data would be distributed evenly across database storage segments when sorting based on sensor ID. Since this is time-series data, virtually all data arriving at the same time will have timestamps around the same time. Using a timestamp early in the key could create hotspots. Using sensor ID first would avoid hotspots but would require more scans to retrieve customer data because multiple customers’ data would be stored in each data block.",gcp-pde,Building and Operationalizing Storage Systems
2407642024,"What is the name of the fully managed, horizontally scalable relational database service in GCP?",Cloud Spanner,gcp-pde,flashcard
330148370,"What is the name of the GCP managed database service that stores data in tables organized by key-value maps, and each row contains data about a single entity and is indexed by a row key?",Bigtable,gcp-pde,flashcard
1320502969,You are developing a new application and will be storing semi-structured data that will only be accessed by a single key. The total volume of data will be at least 40 TB. What GCP database service would you use?,Bigtable. Bigtable is a wide-column NoSQL database that supports semi-structured data and works well with datasets over 1 TB.,gcp-pde,Selecting Appropriate Storage Technologies
1371206255,You are querying a BigQuery table that has been partitioned by time. You create a query and use the --dry_run flag with the bq query command. The amount of data scanned is far more than you expected. What is a possible cause of this?,You did not include _PARTITIONTIME in the WHERE clause to limit the amount of data that needs to be scanned. You probably did not include the pseudo-column _PARTITIONTIME in the WHERE clause to limit the amount of data scanned.,gcp-pde,Building and Operationalizing Storage Systems
2732744520,"A group of data scientists have uploaded multiple time-series datasets to BigQuery over the last year. They have noticed that their queries—which select up to six columns, apply four SQL functions, and group by the day of a timestamp—are taking longer to run and are incurring higher BigQuery costs as they add data. They do not understand why this is the case since they typically work only with the most recent set of data loaded. What would you recommend they consider in order to reduce query latency and query costs?","Partition the table and use clustering. The queries are likely scanning more data than needed. Partitioning the table will enable BigQuery to scan only data within a partition, and clustering will improve the way column data is stored.",gcp-pde,Building and Operationalizing Storage Systems
3987395669,What is Stackdriver Debugger?,Stackdriver Debugger is an application debugger for inspecting the state of a running program that allows developers to insert log statements or take snapshots of the state of an application.,gcp-pde,flashcard
2376809149,"A group of climate scientists is collecting weather data every minute from 10,000 sensors across the globe. Data often arrives near the beginning of a minute, and almost all data arrives within the first 30 seconds of a minute. The data ingestion process is losing some data because servers cannot ingest the data as fast as it is arriving. The scientists have scaled up the number of servers in their managed instance group, but that has not completely eliminated the problem. They do not wish to increase the maximum size of the managed instance group. What else can the scientists do to prevent data loss?","Write data to a Cloud Pub/Sub topic.  write data to a Cloud Pub/Subtopic, which can scale automatically to existing workloads. The ingestion process can read data from the topic and data and then process it. Some data will likely accumulate early in every minute, but the ingestion process can catch up later in the minute after new data stops arriving.",gcp-pde,Selecting Appropriate Storage Technologies
3086705352,What GCP data store option is the best choice for data warehousing and analytic processing?,BigQuery,gcp-pde,flashcard
2966063290,What is precision with respect to machine learning?,Precision is the proportion of positive cases that were correctly identified. This measure is also known as the positive predictive value.,gcp-pde,flashcard
4254114913,What GCP managed service uses network attached storage and provides a filesystem that is accessible from Compute Engine and Kubernetes Engine?,Cloud Filestore,gcp-pde,flashcard
2948273151,What is identity access management (IAM)?,"IAM is a GCP service for implementing fine-grained access controls on resources. IAM allows for the implementation of predefined and custom roles that are more narrowly tailored than older, default GCP primitive roles.",gcp-pde,flashcard
1662799844,"You are migrating several terabytes of historical sensor data to Google Cloud Storage. The data is organized into files with one file per sensor per day. The files are named with the date followed by the sensor ID. After loading 10 percent of the data, you realize that the data loads are not proceeding as fast as expected. What might be the cause?","The filenaming convention uses dates as the first part of the file name. If the files are loaded in this order, they may be creating hotspots when writing the data to Cloud Storage. Since the files have sequential names, they may be loading in lexicographic order and this can create hotspots.",gcp-pde,Building and Operationalizing Storage Systems
2904414419,What two types of Cloud Storage classes are used for storing data that is not frequently accessed?,Nearline and Coldline,gcp-pde,flashcard
717410677,"A team of machine learning engineers are creating a repository of data for training and testing machine learning models. All of the engineers work in the same city, and they all contribute datasets to the repository. The data files will be accessed frequently, usually at least once a week. The data scientists want to minimize their storage costs. They plan to use Cloud Storage; what storage class would you recommend?",Regional. Regional storage is sufficient for serving users in the same geographic location and costs less than multi-regional storage.,gcp-pde,Building and Operationalizing Storage Systems
1998827843,What is recall with respect to machine learning?,Recall is the number of actual positive cases that were correctly identified.,gcp-pde,flashcard
2443075378,"You are running a Redis cache using Cloud Memorystore. One day, you receive an alert notification that the memory usage is exceeding 80 percent. You do not want to scale up the instance, but you need to reduce the amount of memory used. What could you try?","Setting shorter TTLs and trying a different eviction policy. Setting shorter TTLs will make keys eligible for eviction sooner, and a different eviction policy may lead to more evictions. For example, switching from an eviction policy that evicts only keys with a TTL to a policy that can evict any key may reduce memory use.",gcp-pde,Building and Operationalizing Storage Systems
3788577167,You need to collect streaming data and transmit summaries every minute. What GCP service would you use?,Cloud Dataflow,gcp-pde,flashcard
3351760794,What is regional storage?,A Cloud Storage class with monthly availability and a 99.9 percent availability SLA. Objects are redundantly stored across zones in a region.,gcp-pde,flashcard
1669494128,What are hyperparameters?,Hyperparameters are configuration values used to specify model training properties.,gcp-pde,flashcard
1578563596,What is Stackdriver?,"Stackdriver is a set of services for monitoring, logging, tracing, and debugging infrastructure and applications in GCP and other platforms.",gcp-pde,flashcard
3965793826,"A genomics research institute is developing a platform for analyzing data related to genetic diseases. The genomics data is in a specialized format known as FASTQ, which stores nucleotide sequences and quality scores in a text format. Once the files finish uploading, an analysis pipeline runs, reads the data in the FASTQ file, and outputs data to a database. The output is in tabular structure, the data is queried using SQL, and typically queries retrieve only a small number of columns but many rows. What database would you recommend for storing the output of the workflow?","BigQuery. because the output is structured, will be queried with SQL, and will retrieve a large number of rows but few columns, making this a good use case for columnar storage, which BigQuery uses.",gcp-pde,Selecting Appropriate Storage Technologies
3141694374,What is a service account in GCP?,A service account is a form of identity that is owned by an application or virtual machine. Service accounts can be assigned roles to enable the application or virtual machine to perform some task.,gcp-pde,flashcard
2412347849,"The CTO of your company wants to reduce the cost of running an HBase and Hadoop cluster on premises. Only one HBase application is run on the cluster. The cluster currently supports 10 TB of data, but it is expected to double in the next six months. Which of the following managed services would you recommend to replace the on-premises cluster in order to minimize migration and ongoing operational costs?","Cloud Bigtable using the HBase API. Cloud Bigtable using the HBase API would minimize migration efforts, and since Bigtable is a managed service, it would help reduce operational costs.",gcp-pde,Selecting Appropriate Storage Technologies
2965714717,"A data modeler is designing a database to support ad hoc querying, including drilling down and slicing and dicing queries. What kind of data model is the data modeler likely to use?",OLAP.  OLAP data models are designed to support drilling down and slicing and dicing.,gcp-pde,Selecting Appropriate Storage Technologies
2059806623,"A developer is planning a mobile application for your company’s customers to use to track information about their accounts. The developer is asking for your advice on storage technologies. In one case, the developer explains that they want to write messages each time a significant event occurs, such as the client opening, viewing, or deleting an account. This data is collected for compliance reasons, and the developer wants to minimize administrative overhead. What system would you recommend for storing this data?",Stackdriver Logging. Stackdriver Logging is the best option because it is a managed service designed for storing logging data. Neither Option A or B is as good a fit because the developer would have to design and maintain a relational data model and user interface to view and manage log data.,gcp-pde,Selecting Appropriate Storage Technologies
2802290347,Which GCP compute service is well suited to event processing?,Cloud Functions,gcp-pde,flashcard
1941519533,"A team of analysts has collected several CSV datasets with a total size of 50 GB. They plan to store the datasets in GCP and use Compute Engine instances to run RStudio, an interactive statistical application. Data will be loaded into RStudio using an RStudio data loading tool. Which of the following is the most appropriate GCP storage service for the datasets?","Cloud Storage.  Cloud Storage, because the data in the files is treated as an atomic unit of data that is loaded into RStudio.",gcp-pde,Selecting Appropriate Storage Technologies
48899512,What is Stackdriver Trace?,Stackdriver Trace is a distributed tracing system for collecting latency data from an application that helps developers understand where applications are spending their time and to identify cases where performance is degrading.,gcp-pde,flashcard
3938530507,What is accuracy with respect to machine learning?,Accuracy is the measure of how often a machine learning algorithm makes a correct prediction.,gcp-pde,flashcard
1041512085,A software developer asks your advice about storing data. The developer has hundreds of thousands of 10 KB JSON objects that need to be searchable by most attributes in the JSON structure. What kind of NoSQL database would you recommend?,"Document database. A document database could store the volume of data, and it provides for indexing on columns other than a single key.",gcp-pde,Selecting Appropriate Storage Technologies
900900270,A Cloud Spanner database is being deployed in us-west1 and will have to store up to 20 TB of data. What is the minimum number of nodes required?,"10. Since each node can store 2 TB, it will require at least 10 nodes.",gcp-pde,Building and Operationalizing Storage Systems
2066464057,What are the three types of IAM roles?,"Primitive, predefined, and custom",gcp-pde,flashcard
2107397455,"As a member of a team of game developers, you have been tasked with devising a way to track players’ possessions. Possessions may be purchased from a catalog, traded with other players, or awarded for game activities. Possessions are categorized as clothing, tools, books, and coins. Players may have any number of possessions of any type. Players can search for other players who have particular possession types to facilitate trading. The game designer has informed you that there will likely be new types of possessions and ways to acquire them in the future. What kind of a data store would you recommend using?",Document database. because the requirements call for a semi-structured schema. You will need to search players’ possessions and not just look them up using a single key because of the requirement for facilitating trading.,gcp-pde,Selecting Appropriate Storage Technologies
1622058459,What is General Data Protection Regulation (GDPR)?,General Data Protection Regulation is a European Union privacy directive with strict data access and retention controls.,gcp-pde,flashcard
530783732,Which GCP service is used for monitoring applications and infrastructure?,Stackdriver Monitoring,gcp-pde,flashcard
864514509,"If you require a global, strongly consistent transactional data store, which GCP service is the best choice?",Cloud Spanner,gcp-pde,flashcard
3052948379,What is a service-level agreement (SLA)?,A service-level agreement is an agreement between a provider of a service and a customer using the service. SLAs define responsibilities for delivering a service and consequences when responsibilities are not met.,gcp-pde,flashcard
2064870651,What is Cloud Firestore?,"Cloud Firestore is a serverless, managed NoSQL document database used for storing, synchronizing, and querying mobile and web application data.",gcp-pde,flashcard
4099558622,What is Cloud Storage?,An object storage service providing web access to scalable storage. Objects can be stored in different storage classes providing different levels of availability and access charges. Durability is the same for all storage classes: 99.999999999 percent.,gcp-pde,flashcard
398815995,What GCP managed service can you use as a replacement for Cassandra?,Bigtable,gcp-pde,flashcard
897377128,The Apache Beam stream processing framework is implemented by which GCP service?,Cloud Dataflow,gcp-pde,flashcard
2197651862,What is block storage?,A storage model that builds on contiguous sets of bytes known as blocks,gcp-pde,flashcard
287758130,What measure describes the likelihood that a stored object will be retrievable in the future?,Durability,gcp-pde,flashcard
744379313,What term describes the ability of a service to adapt its infrastructure to the load on the system?,Scalability,gcp-pde,flashcard
2958348145,What kind of data model is used by Cloud Datastore?,Document,gcp-pde,flashcard
2738311219,What is a service-level indicator (SLI)?,"A service-level indicator is a metric that reflects how well a service-level objective is being met. Examples include latency, throughput, and error rate.",gcp-pde,flashcard
4129520445,Your department is planning to expand the use of BigQuery. The CFO has asked you to investigate whether the company should invest in flat-rate billing for BigQuery. What tools and data would you use to help answer that question?,"Stackdriver Monitoring and slot utilization metrics. Stackdriver Monitoring collects metrics, and the slot metrics are the ones that show resource utilization related to queries.",gcp-pde,Building and Operationalizing Storage Systems
3680952904,What is a persistent disk?,"A durable block storage system for GCP, available in solid-state and hard disk drive types.",gcp-pde,flashcard
1548601958,What Google Cloud Platform service can be used for importing data to and exporting data from Cloud Spanner?,Cloud Dataflow,gcp-pde,flashcard
1121668390,What is a bucket in terms of Cloud Storage?,"A bucket is space for holding objects in Cloud Storage. Bucket names are unique across Cloud Storage. Buckets have a geographic location and a storage class. Storage classes are multi-regional, regional, nearline, and coldline.",gcp-pde,flashcard
1189871821,"A database administrator (DBA) who is new to Google Cloud has asked for your help configuring network access to a Cloud SQL PostgreSQL database. The DBA wants to ensure that traffic is encrypted while minimizing administrative tasks, such as managing SQL certificates. What would you recommend?",Use Cloud SQL Proxy.  Cloud SQL Proxy. Cloud SQL Proxy provides secure access to Second Generation instances without you having to create allow lists or configure SSL. The proxy manages authentication and automatically encrypts data.,gcp-pde,Building and Operationalizing Storage Systems
855567314,"When using versioning on a bucket, what is the latest version of the object called?",Live version,gcp-pde,flashcard
2061485647,Why do all buckets in Cloud Storage need to have a unique name?,"Google Cloud Storage uses a global namespace for bucket names, so all bucket names must have unique names.",gcp-pde,flashcard
3706706673,"A team of game developers is using Cloud Firestore to store player data, including character description, character state, and possessions. Descriptions are up to a 60 character alphanumeric string that is set when the character is created and not updated. Character state includes health score, active time, and passive time. When they are updated, they are all updated at the same time. Possessions are updated whenever the character acquires or loses a possession. Possessions may be complex objects, such as bags of items, where each item may be a simple object or another complex object. Simple objects are described with a character string. Complex objects have multiple properties. How would you model player data in Cloud Firestore?","Store description as a string; character state as an entity with properties for health score, active time, and passive time; and possessions as an entity that may have embedded entities. Description can be represented in a string. Health consists of three properties that are accessed together, so they can be grouped into an entity. Possessions need a recursive representation since a possession can include sets of other possessions.",gcp-pde,Building and Operationalizing Storage Systems
2516470584,What is a memory cache?,"A high-speed, random access memory for storing frequently used data. GCP's Memorystore provides a managed caching service.",gcp-pde,flashcard
2069630727,What is the Health Insurance Portability and Accountability Act (HIPAA)?,The Health Insurance Portability and Accountability Act is a U.S. healthcare regulation with rigorous data access and privacy rules.,gcp-pde,flashcard
1315174616,What service enables engineers to deploy an adequate number of instances needed to meet the load on a system?,Autoscaling,gcp-pde,flashcard
147576906,What is a measure of a user's ability to access a working service over a period of time?,Availability,gcp-pde,flashcard
1119773561,What are the continuous operations of a system at sufficient capacity to meet the demands of ongoing workloads called?,High availability,gcp-pde,flashcard
2648999098,What are the four storage classes in Cloud Storage?,"Regional, Multi-regional, Nearline, and Coldline",gcp-pde,flashcard
21955266,"What type of expenditures are used to acquire assets, such as computer equipment, vehicles, and land?",Capital expenditures,gcp-pde,flashcard
784159516,What is BigQuery?,BigQuery is a petabyte-scale data warehousing and analytics processing managed service that uses relational tables to organize data and provides SQL as the query language.,gcp-pde,flashcard
1878215182,"You are querying a Cloud Firestore collection of order entities searching for all orders that were created today and have a total sales amount of greater than $100. You have not excluded any indexes, and you have not created any additional indexes using index.yaml. What do you expect the results to be?","No entities returned. No entities are returned. The query requires a composite index, but the question stated that no additional indexes were created. All other answers are wrong because querying by property other than a key will only return entities found in an index.",gcp-pde,Building and Operationalizing Storage Systems
506883469,What is the name of Google Cloud's managed Kubernetes service?,Google Kubernetes Engine (GKE),gcp-pde,flashcard
3796653638,A software developer asks your advice about storing data. The developer has hundreds of thousands of 1 KB JSON objects that need to be accessed in sub-millisecond times if possible. All objects are referenced by a key. There is no need to look up values by the contents of the JSON structure. What kind of NoSQL database would you recommend?,Key-value database. This is a good used case for key-value databases because the value is looked up by key only and the value is a JSON structure.,gcp-pde,Selecting Appropriate Storage Technologies
